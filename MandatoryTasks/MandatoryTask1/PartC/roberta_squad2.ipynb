{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95388785-ae0d-45b8-bfdf-6bb9b7ae5beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\LOCALACCOUNT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\LOCALACCOUNT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\LOCALACCOUNT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install -q datasets evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80510a58-29cd-40c1-8e2c-cc1dcc4580bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we import all the required libs\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "import evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85fdaece-1934-4817-afa5-1f32ab979580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the NewsQA dataset from HF\n",
    "\n",
    "dataset = load_dataset(\"lucadiliello/newsqa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9d97ef-03dd-45e7-a009-16903a125953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d65a111b1c5b4db5aeb2078ef444dcce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/79.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LOCALACCOUNT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\LOCALACCOUNT\\.cache\\huggingface\\hub\\models--deepset--roberta-base-squad2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aeb3b0c7e27447cbccd3cb1d62ed696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ea2c08b998b42ea9bc39dadac8117d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15f05b774a0242b4974086d60768f589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b2be9f2256a430eb34925b25ddeddf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ec3b8a90c724471ab65cdf7b8df05d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/496M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LOCALACCOUNT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\LOCALACCOUNT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\_monitor.py\", line 84, in run\n",
      "    instance.refresh(nolock=True)\n",
      "  File \"C:\\Users\\LOCALACCOUNT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\std.py\", line 1347, in refresh\n",
      "    self.display()\n",
      "  File \"C:\\Users\\LOCALACCOUNT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\notebook.py\", line 171, in display\n",
      "    rtext.value = right\n",
      "    ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LOCALACCOUNT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\traitlets\\traitlets.py\", line 716, in __set__\n",
      "    self.set(obj, value)\n",
      "  File \"C:\\Users\\LOCALACCOUNT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\traitlets\\traitlets.py\", line 706, in set\n",
      "    obj._notify_trait(self.name, old_value, new_value)\n",
      "  File \"C:\\Users\\LOCALACCOUNT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\traitlets\\traitlets.py\", line 1513, in _notify_trait\n",
      "    self.notify_change(\n",
      "  File \"C:\\Users\\LOCALACCOUNT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipywidgets\\widgets\\widget.py\", line 700, in notify_change\n",
      "    self.send_state(key=name)\n",
      "  File \"C:\\Users\\LOCALACCOUNT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipywidgets\\widgets\\widget.py\", line 586, in send_state\n",
      "    self._send(msg, buffers=buffers)\n",
      "  File \"C:\\Users\\LOCALACCOUNT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipywidgets\\widgets\\widget.py\", line 825, in _send\n",
      "    self.comm.send(data=msg, buffers=buffers)\n",
      "  File \"C:\\Users\\LOCALACCOUNT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\comm\\base_comm.py\", line 144, in send\n",
      "    self.publish_msg(\n",
      "  File \"C:\\Users\\LOCALACCOUNT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\comm\\comm.py\", line 42, in publish_msg\n",
      "    parent=self.kernel.get_parent(),\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LOCALACCOUNT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 797, in get_parent\n",
      "    return self._shell_parent.get()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "LookupError: <ContextVar name='shell_parent' at 0x000002CFA6703970>\n"
     ]
    }
   ],
   "source": [
    "# Now we load a pre-trained RoBERTa model that has already been trained on squad2\n",
    "model_name = \"deepset/roberta-base-squad2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418e6b5a-ebd6-4397-a35a-c4f9c0d63f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This helper function is used to take the text and the answer start\n",
    "# fields from the answers in the dataset\n",
    "# Some samples might have missing values and stuff so handeling that tooo\n",
    "def _extract_answer_info(answer_obj):\n",
    "    if isinstance(answer_obj, dict):\n",
    "        texts = answer_obj.get(\"text\", [])\n",
    "        starts = answer_obj.get(\"answer_start\", [])\n",
    "        if len(texts) == 0 or len(starts) == 0:\n",
    "            return None, []\n",
    "        return texts[0], starts\n",
    "    if isinstance(answer_obj, list):\n",
    "        if len(answer_obj) == 0:\n",
    "            return None, []\n",
    "        first = answer_obj[0]\n",
    "        if isinstance(first, dict):\n",
    "            texts = first.get(\"text\", [])\n",
    "            starts = first.get(\"answer_start\", [])\n",
    "            if len(texts) == 0 or len(starts) == 0:\n",
    "                return None, []\n",
    "            return texts[0], starts\n",
    "    return None, []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b6a44a-3410-4af8-a0c6-91b604cafa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It tokenizes both the question and the context\n",
    "def preprocess_function(examples):\n",
    "    questions = [q.strip() if q else \"\" for q in examples[\"question\"]]\n",
    "    contexts = [c if c else \"\" for c in examples[\"context\"]]\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        contexts,\n",
    "        max_length=384,\n",
    "        truncation=\"only_second\",\n",
    "        stride=128,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    sample_mapping = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        input_ids = inputs[\"input_ids\"][i]\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "        sample_index = sample_mapping[i]\n",
    "        answer_obj = examples[\"answers\"][sample_index]\n",
    "\n",
    "        answer_text, answer_starts = _extract_answer_info(answer_obj)\n",
    "        if answer_text is None or len(answer_starts) == 0:\n",
    "            start_positions.append(cls_index)\n",
    "            end_positions.append(cls_index)\n",
    "            continue\n",
    "\n",
    "        start_char = int(answer_starts[0])\n",
    "        end_char = start_char + len(answer_text)\n",
    "\n",
    "        token_start_index = 0\n",
    "        while sequence_ids[token_start_index] != 1:\n",
    "            token_start_index += 1\n",
    "        token_end_index = len(input_ids) - 1\n",
    "        while sequence_ids[token_end_index] != 1:\n",
    "            token_end_index -= 1\n",
    "\n",
    "        if not (start_char >= offsets[token_start_index][0] and end_char <= offsets[token_end_index][1]):\n",
    "            start_positions.append(cls_index)\n",
    "            end_positions.append(cls_index)\n",
    "        else:\n",
    "            while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "                token_start_index += 1\n",
    "            start_positions.append(token_start_index - 1)\n",
    "\n",
    "            while token_end_index >= 0 and offsets[token_end_index][1] >= end_char:\n",
    "                token_end_index -= 1\n",
    "            end_positions.append(token_end_index + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5e25e6-9567-4990-b43c-89c8c2071539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the dataset is large, we only take a small portion \n",
    "train_subset = dataset[\"train\"].select(range(2000))\n",
    "val_subset   = dataset[\"validation\"].select(range(500))\n",
    "\n",
    "# Applying the preprocessing function to both training and validation samples\n",
    "tokenized_train = train_subset.map(preprocess_function, batched=True, remove_columns=train_subset.column_names)\n",
    "tokenized_val   = val_subset.map(preprocess_function, batched=True, remove_columns=val_subset.column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d645c3f7-b6cf-4a31-a899-d79263d57819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to Hypertune it!\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"roberta_qa_model\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    save_total_limit=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0c0f9b-fdb7-4b2d-94e6-3597fcffe394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the Trainer class which handles training and evaluation for us\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    tokenizer=tokenizer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce4e69c-4872-4394-8948-3518557fc7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec71e548-c59a-4e75-bdcf-75e9afe8c657",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluvating it\n",
    "metric = evaluate.load(\"squad\")\n",
    "\n",
    "def compute_metrics_from_logits(start_logits, end_logits, features, raw_examples):\n",
    "    preds = []\n",
    "    for i, (s_log, e_log) in enumerate(zip(start_logits, end_logits)):\n",
    "        s = int(np.argmax(s_log))\n",
    "        e = int(np.argmax(e_log))\n",
    "        if s > e:\n",
    "            pred_text = \"\"\n",
    "        else:\n",
    "            pred_text = tokenizer.decode(features[\"input_ids\"][i][s:e+1], skip_special_tokens=True).strip()\n",
    "        preds.append({\"id\": str(i), \"prediction_text\": pred_text})\n",
    "\n",
    "    refs = []\n",
    "    for i in range(len(raw_examples)):\n",
    "        txt, starts = _extract_answer_info(raw_examples[i][\"answers\"])\n",
    "        if txt is None:\n",
    "            refs.append({\"id\": str(i), \"answers\": {\"text\": [], \"answer_start\": []}})\n",
    "        else:\n",
    "            refs.append({\"id\": str(i), \"answers\": {\"text\": [txt], \"answer_start\": [int(starts[0]) if len(starts)>0 else 0]}})\n",
    "    return metric.compute(predictions=preds, references=refs)\n",
    "\n",
    "predictions = trainer.predict(tokenized_val)\n",
    "start_logits, end_logits = predictions.predictions\n",
    "results = compute_metrics_from_logits(start_logits, end_logits, tokenized_val, val_subset)\n",
    "\n",
    "print(\"Evaluation results:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ca26ae-f8b4-4fb7-ad84-9ac4c174c3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying in the context\n",
    "context = \"Apple Inc. was founded by Steve Jobs, Steve Wozniak, and Ronald Wayne in April 1976.\"\n",
    "question = \"Who founded Apple Inc.?\"\n",
    "\n",
    "inputs = tokenizer(question, context, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "s = int(np.argmax(outputs.start_logits.detach().numpy()))\n",
    "e = int(np.argmax(outputs.end_logits.detach().numpy()))\n",
    "\n",
    "print(\"QA Test:\", tokenizer.decode(inputs[\"input_ids\"][0][s:e+1], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a2fd1c-7d94-421b-b755-52319e780b69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec761630-611c-49b3-a53d-e8138ded9c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5ba49a-3849-41ca-9dd1-b5272e2233bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d93c2f-2912-452b-a70b-3feae514e1f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7c7f17-c64c-4a1d-b7a7-0dd63c799d1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
