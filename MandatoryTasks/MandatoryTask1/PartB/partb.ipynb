{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KjVmeuyrOGF"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets sentencepiece torch\n",
        "\n",
        "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
        "from datasets import load_dataset\n",
        "\n",
        "model_name = \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "tokenizer = MBart50TokenizerFast.from_pretrained(model_name)\n",
        "model = MBartForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "src_lang = \"en_XX\"\n",
        "target_lang = \"fr_XX\"\n",
        "\n",
        "dataset = load_dataset(\"ag_news\", split=\"train\")\n",
        "texts = [item[\"text\"] for item in dataset.select(range(5))]\n",
        "\n",
        "def translate_text(text, src_lang, tgt_lang):\n",
        "    tokenizer.src_lang = src_lang\n",
        "    encoded = tokenizer(text, return_tensors=\"pt\")\n",
        "    generated_tokens = model.generate(**encoded, forced_bos_token_id=tokenizer.lang_code_to_id[tgt_lang])\n",
        "    return tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n",
        "\n",
        "for idx, text in enumerate(texts):\n",
        "    print(f\"\\nOriginal English Text {idx + 1}:\")\n",
        "    print(text)\n",
        "    translation = translate_text(text, src_lang, target_lang)\n",
        "    print(f\"\\nTranslation (French):\")\n",
        "    print(translation)\n"
      ]
    }
  ]
}